1. See pdf file in the same folder
2. ENIAC: ENIAC stands for "Electronic Numerical Integrator and Computer."
3. Representation of Data in Computers: Data is represented by integers in computers because electronic circuits can easily represent two states, often denoted as 0 and 1. This binary representation simplifies the design of digital circuits and allows for efficient storage and manipulation of data.
4. Fastest Part of Computer Memory: The fastest part of computer memory is the register memory.
5. Slowest Storage Device Integrated with Computers: The slowest storage device integrated with computers is typically the hard disk drive (HDD).
6. Smallest Unit of Information: The smallest unit of information in computer science is a bit.
7. Closest Programming Language to Machine Code:
(A) Assembly language is the closest programming language to machine code.
(B) It does need interpretation to become machine-comprehensible.
8. Oldest High-Level Programming Language Still in Active Use:
(A) Fortran is one of the oldest high-level programming languages still in active daily use.
(B) It is around seven decades old, created in the 1950s.
9. Second-Generation Programming Language:
(A) Assembly language is considered a second-generation programming language.
(B) Fortran, C, C++, MATLAB, Python, R belong to the third generation of programming languages.
10. C was created in the 1970s, C++ in the 1980s, and MATLAB/Python in the 1980s and 1990s, respectively.
11. B is an ancestor programming language of C.
12. C++ is an extension of the C programming language.
13. MATLAB's ancestor is Fortran, and Python's ancestor is ABC.
14. The register memory is the fastest part of the memory hierarchy in modern computers.
15. The smallest memory unit is a bit in the memory hierarchy of modern computers.
16. Access to register memory is significantly faster than RAM in modern computers.
17. Access to RAM is much faster than typical HDD hard drives in modern computers.
18. Access to RAM is much faster than typical HDD hard drives in modern computers.
19. Transistors in computers are primarily used for amplification, switching, and signal modulation.
20. Adding more transistors does not necessarily make computers faster due to power consumption, heat dissipation, and design complexity.
21. The three tasks within a CPU cycle are fetch, decode, and execute.
22. Yes, a powerful computer with more CPU cycles can be slower if it is not efficiently utilizing those cycles due to other bottlenecks, such as memory access or I/O.
23. Memory access is often a bottleneck in modern computers compared to CPU clocks.
24. Dennard Scaling refers to the scaling of MOSFETs to maintain constant power density. MOSFET scaling involves reducing the size of transistors in integrated circuits. Moore's Law is a prediction by Gordon Moore that the number of transistors on a microchip would double approximately every two years
25.(1)You would need 18,446,744,073,709,551,615 grains to fill the last (64th) square incrementally. Overall, you would need twice that amount minus one for all squares. This is an astronomical number, far beyond a pound of rice
(2)You would need 9,223,372,036,854,775,808 grains to fill the last (64th) square geometrically.
(3) With 2 trillion pounds of rice produced annually, it would take more than a million years to produce the required amount for the incremental placement on the chessboard.
26. 
27.(1) Conditional branching (if-else statements).      
(2) Unconditional branching (loops and jumps).      
(3) Memory storage and retrieval.         
28. In a 2-dimensional plot, exponential behavior would show a constant rate of growth, leading to a straight line when plotted on a logarithmic scale. Power-law behavior would display a straight line on a logarithmic scale but with a different slope, indicating a slower rate of growth or decay.   
   

    








